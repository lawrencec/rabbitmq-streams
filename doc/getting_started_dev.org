#+TITLE:     Getting Started with RabbitMQ Streams
#+DATE:      2009-09-11 Fri
#+LANGUAGE:  en
#+STARTUP:   odd
#+OPTIONS:   H:4 num:t toc:t \n:nil @:t ::t |:t ^:nil -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc timestamp:t author:nil
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:nil path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LINK_UP:
#+LINK_HOME:
#+STYLE: <link rel="stylesheet" type="text/css" href="stylesheet.css" />
* If you want to...
 - know more about what it's all about and how it all works, keep reading.
 - add new means of supplying or publishing data feeds, see [[*Writing .* Servers][Writing Servers]].
 - make new ways to manipulate data feeds, see [[*Writing%20PipelineComponents][Writing PipelineComponents]].
 - let people write plugins in a new language, see [[*WritingHarnesses][Writing Harnesses]].
 - hack about with the core code -- read the whole lot, but esp. [[*The Feedshub Architecture in more detail][The Feedshub Architecture in more detail]].

* General Overview
RabbitMQ Streams is a stream based-architecture (surprisingly enough)
conceived to bring more order and manageability to the BBC's massive feed
infrastructure (see [[http://www.bbc.co.uk/blogs/radiolabs/2009/04/introducing_bbc_feeds_hub.shtml][this BBC radiolabs blog entry]]; the BBC have tasked us at
[[http://www.lshift.net][LShift]] with some of the design and development work for their Feedshub project
and you can find more background and updates on the [[http://www.lshift.net/blog/tag/feedshub][LShift blog]]).

However the Streams framework is very general and not limited to working with
Atom/RSS/... Feeds (for example binary data can be handled efficiently as
well). In a way you could think of Streams as a distributed, robust,
scalable, secure, user-friendly and manageable version of Unix pipes.

The basic logical building blocks are /Sources/ and /Sinks/ (=Servers=) of
data and /Feeds/ (*NB:* Feed in this sense has nothing to do with RSS/Atom/etc.;
/Processing Pipeline/ would be more accurate description) composed of
=PipelineComponents= which can route (e.g. based on regexp matches on Atom
feed entries) merge and transform the data in arbitrary ways (e.g. by applying
xslt transforms), as depicted below:

#+CAPTION: Flow of Information in RabbitMQ Streams (simplified excerpt).
#+LABEL:   fig:flow-simplified
    [[./flow-simplified.png]]

=Servers= as well as =PipelineComponents= (jointly referred to as =Plugins=)
can currently be written in Java and other JVM based languages (for example
several plugins are written in scala, and using JRuby or Jython should be
equally straightforward). Plugins require almost no boilerplate (see e.g.
[[../plugins/regexp_split/src/main//java/com/rabbitmq/streams/plugins/regexp/split/RegexpSplit.java][RegexpSplit.java]]). Support for other languages can be added straightforwardly
by creating an appropriate [[*Writing][=Harness=]] (adding e.g. Ruby would be easy because
plugins are essentially just programs following a simple protocol). There used
to be a python harness, but since the Plugin architecture changed quite a bit
and is indeed likely to change even more in the near future (we plan to
replace the current imperative design with a more functional one), we decided
to concentrate on the Java harness until the overall design stabilizes.

Robustness, scalability etc. are achieved through the "plumbing" layer which
is transparent to Plugin authors and (mostly) consists of the Streams-specific
=Orchestrator= (which takes care setting up all the wiring between components)
as well as two proven off-the-shelf [[http://www.rabbitmq.com][RabbitMQ]] (the messaging broker which
provides high-performance, fault-tolerant queued communication between
components) and Apache's [[http://couchdb.apache.org/][CouchDB]] (which provides a store for configuration and
persistent state for =Plugins= which require it)[fn:1]. Since these core
components as well as the =Orchestrator= are written in [[http://erlang.org][Erlang]], they can
leverage Erlang's excellent infrastructure for creating highly-available and
fault-tolerant services.

* Developing
Although many of the core components of Streams are written in Erlang, relax!
No Erlang skills are required for the most common development task: writing
additional Sources/Sinks/Transformers ([[*Plugins][=Plugins=]]). The same is true for
extending the set of languages that plugins can be written by writing
additional [[*Harnesses][=Harnesses=]].

For those who want to dig deeper into the [[*Feeshub Architecture][architecture of Streams]] it is
useful to gain some familiarity with [[http://en.wikipedia.org/wiki/Advanced_Message_Queuing_Protocol][AMQP]] (and [[http://www.rabbitmq.com][RabbitMQ]] in
particular); [[http://couchdb.apache.org/][CouchDB]] and [[http://erlang.org][Erlang]] skills would also help. The links have
pointers to more in-depth info, but the following links are useful to hit the
ground running:

 - [[http://somic.org/d/samovskiy-amqp-rabbitmq-cohesiveft.pdf][A short presentation on AMQP and RabbitMQ]]
 - [[http://books.couchdb.org/relax/intro/getting-started][Getting Started with CouchDB (from the CouchDB Book)]]

* Plugins
Currently the easiest way of Writing a plugin (say =acme_frotz=) in Java or
another JVM language involves creating a subdirectory =plugins/acme_frotz=
with some files in it. We will eventually create an maven archetype or some
other means of automatization for this task, but at the moment the easiest way
to get going is to just adapt an existing plugin (we will take the =xslt=
=PipelineComponent= as a starting point, if you'd like to write a
Server/Gatway instead use e.g. =socket_source= (Ingress) or
=socket_destination= (Egress) as a template instead).

 1. add a line =<module>websubscriber</module>= to =plugins/pom.xml= (this is
    mostly for IDE support).
 2. Copy some existing plugin and rename as appropriate, e.g.
#+BEGIN_SRC sh
cd plugins
cp -r xslt acme_frotz
FILES=$(find acme_frotz -type f -name '*')
perl -i -pe 's/xslt/acme_frotz/g; s/Xslt/AcmeFrotz/g' $FILES
rename 's/xslt/acme_frotz/g; s/Xslt/AcmeFrotz/g' $FILES
mv src/main/java/com/rabbitmq/streams src/main/java/com/MY_DOMAIN/
mv src/test/java/com/rabbitmq/streams src/test/java/com/MY_DOMAIN/
#+END_SRC
 3. Edit =acme_frotz/plugin.js= which specifies the configuration/wiring and meta-info of
    the plugin and specify the author, parameters and wiring (more below)
 4. Make sure the =acme_frotz/pom.xml= file lists the right dependencies
 5. Edit the actual java file =acme_frotz/src/main/java/com/MY_DOMAIN/plugins/AcmeFrotzProcessor.java=

The harness also provides the plugin with an abstract facility to store state
that should persists between restarts of the same instance (=Plugin.getState=,
=Plugin.setState=); for more involved needs a plugin specification can also
request a full-blown private database but the details are still being hashed
out.

*** =plugin.js= (Per-plugin (class) [[http://json.org][json]] configuration)
#+BEGIN_SRC js2
File plugin.js =
// applies to both pipeline components and servers
{ "name": "The ACME Frotz", // FIXME this will change to "label"
  "author": { "name":  "John Doe",
              "email": "jondoe@example.tld" },
  "help": "ACME Frotz mogrifies bartz-transputed bits.",
  "type": "plugin-specification", // FIXME this will go
  "harness": "java", // same for all JVM based languages
  "subtype": "pipeline_component", // or  "server"  // FIXME this will change to "plugin_type"
  "global_configuration_specification": [], // FIXME get rid of this
  /* the /schema/ of the configuration that must be provided per plugin
    instance, i.e. the plugin-configuration variable names and types.
   */
  "configuration_specification":  [ { "name": "port", "label": "Port", "default": 8080,
                                      "help": "int < 65536" }
                                    // ...
                                  ],
  /* configuration per terminal (terminal ONLY) */ //FIXME AMWS: "server ONLY"?
  "destination_specification": [ { "name": "title", "label": "Title for RSS"}
                                 // ...
                               ],
  /* configuration per terminal (terminal ONLY) */ //FIXME AMWS: "server ONLY"?
  "source_specification": [ { "name": "url", "label": "URL of RSS", "type": "URL" }
                            // ...
                          ],

  /* configuration per feed component (feed_component ONLY) */
  "inputs_specification": [ { "name": "input" }
                            // ...
                          ],
  /* configuration per feed component (feed_component ONLY) */
  "outputs_specification": [ { "name": "output" }
                           //...
                           ],
   /* Slightly experimental and not much (at all?) used yet, but this is
    intended for plugins which need proper database functionality (in addition
    to persistent plugin state, as per Plugin.getState Plugin.setState). If
    your plugin doesn't neeed a database, just use null.
   */
  "database_specification": null // or {} ; initial values for the per instance db
}
#+END_SRC
*** Some Guidelines applying to all types of Plugins
The Harness provides abstract interfaces to the Plugin to access (inter alia)
the following functionality:

 - (hooked-up) input/output channels (as specified by =plugin.js=) ::
   =plugins/regexp_split=, which implements simple regexp-based routing, can
   serve as a template for doing that, it specifies one input channel
   (unimaginatively named "input") and two output channels ("positive" and
   "negative", for messages that respectively match and don't match the
   regexp) in its =plugin.js=. In the class constructor the "input" channel is
   registered with an InputReader =registerInput("input", input)= which is
   instantiated from an anonymous subclass of InputReader:

#+BEGIN_SRC java
  // for each input
  InputReader input = new InputReader() {
    @Override  // do something plugin-specific with the received message
    public void handleMessage(InputMessage msg) throws PluginException {
       ... // do stuff with input msg
       if (matcher.matches()) // if the input messages matches the regexp
         publishToChannel("positive", msg);
       else
         publishToChannel("negative", msg);

#+END_SRC
 - logging and notification facilities ::
   - =log.debug("Current value of froboz is " + froboz)= adds a debug message to the
     streams log (other log types include =fatal= and =info=).

   - =notifier.notify(NotificationType.BadData, "Input XML isn't well-formed")=
     sends a notification.

   Technically the main difference between notifications and loggings is that
   notifications are sent like other Messages, which means they can be routed
   filtered and transformed by streams, whereas log messages are just written
   directly to the central log file. Logically, notifications are intended for
   aspects that are relevant to the business logic whilst logging is intended
   for system administration and troubleshooting.

 - data storage facilities :: Some plugins need need to remember state between
   messages and since streams is designed for robustness, plugins need a
   facility to persist such state in case of restarts or crashes. For example
   =plugins/timeout= detects if a channel hasn't been written to for a certain
   amount of time and sends an alert. To make sure that this happens even if
   the plugin instance has died in-between, it stores the time it should send
   the next alert persistently and checks it on waking up -- if it is in the
   past, it fires of an alert immediately. This is handled by the =getState()=
   and =setState()= methods, which allow persisting the state serialized as
   json objects.

   The =database= argument is intended for plugins whose needs aren't
   satsified by the simple persistent state explained above, but remains
   experimental at this stage.

*** TODO add notification etc. javadoc links


Note: since the Harness uses =stdin= and =stdout= for its own purposes your
plugin shouldn't try to use these internally.
*** Testing Plugins
There are currently two ways to write tests for Plugins
***** Using "normal" JUnit/Mockito unittests in Java (or Scala  etc.)
This method offers best IDE integration, e.g. such tests can be easily
debugged in and IDE like netbeans or Eclipse, but on the downside is somewhat
language specific and needs awareness of the plugin implementation details.

Some helper classes for mocking up important components of the framework can
be found =com.rabbitmq.streams.harness.testsupport=. For a simple java example
see e.g. =RegexpSplitTest.java= of the =regexp_split= plugin and for an
indiomatic scala example e.g. =DataTimeoutTest.scala= of the =timeout= plugin.

***** Writing functional input-expect output (=.io=) tests
*Warning:* the driver code for the functional tests is currently pretty
kludgy and brittle and portions need to be rewritten, so although it works
most of time strange errors can occur.

The =plugin_test_harness.py= script allows one to run a plugin in isolation
for testing purposes. It loads up the plugin with a configuration file,
creates a dummy database and defines a simple protocol for sending data to
channels by writing to stdout. Here is an example (a =regexp_replace= that
reads text from channel =input= and writes the regexp substituion to channel
=positive= if therere is a match and the unmodified string to =negative= if
there isn't):

#+BEGIN_SRC sh
# after starting streams
python bin/plugin_test_harness.py --verbose plugins/regexp_replace <(echo -E '
 {"expressions": [{"regexp": "(.)$1$1", "replacement": "[3 x \"$1\"]",
                   "multiline": false, "dotall": false, "caseinsensitive": false }]}' )
#+END_SRC

Then type in the following (*NB* although it is not visible note that the left
and right columns are seperated by a tab, not (just) spaces):

#+BEGIN_SRC io
>input	sausages

<positive	sausages

#+END_SRC

You should see the following on the screen:
#+BEGIN_SRC io
>input	no tripples in this line
...	or this one
...	here we end, still no tripples

<negative	no tripples in this line
...         	or this one
...         	here we end, still no tripples
>input	next come some tttrrriiippples

<positive	next come some [3 x "t"][3 x "r"][3 x "i"][3 x "p"]les
#+END_SRC

******* Running functional tests in the debugger
It is possible to attach a debugger to IO-tests for a plugin written in a JVM
language by adding an extra flag:
#+BEGIN_SRC sh
DEBUG_ARGS="-Xdebug -Xrunjdwp:transport=dt_socket,address=8998,server=y"
python bin/plugin_test_harness.py -DJVMARGS="$DEBUG_ARGS"  [...]
#+END_SRC
Then in your IDE add the breakpoints you want and attach the debugger (make
sure the port is what you specified above, i.e. 8998).

******* the =.io= format in detail

The input format is simple:
 - a line starting with =#= is treated as a comment and ignored
 - a line starting with =>CHANNEL_NAME= followed by an optional =json=
   dictionary (see below) and optional spaces and finally a tab then some
   =text= is the begin of a message to input-channel =CHANNEL_NAME= (the =>=
   may be omitted but an output-channel message always starts with =<=).
 - a line starting with =...=, optional spaces and a tab, followed by
   =more-text= continues the message on the previous line (the =...= may be
   omitted)
 - an empty line on its own sends of all the accumulated inputs to the
   respective channels
 - in the text part (after the tab) all whitespace, special characters etc.
   are preserved verbatim (so any possible text, including binary can be
   input), but the ultimate newline of each message part is omitted (otherwise
   there would be no way to write input that didn't end in a newline).

: >input	start of text
: ...   	one more line
: ...   	final line, but this newline will

   is analogous to the following python string definition:

#+BEGIN_SRC python
input = """start of text
one more line
final line, but no trailing newline"""
#+END_SRC
***** Magic channels
Channels with ALLCAPS names are reserved for magic pseudochannels. An example
is
#+BEGIN_SRC io
>SLEEP	3s
#+END_SRC
which will sleep 3 seconds before continuing. This is useful for testing
timing sensitive plugins, such as =../plugins/data_timeout=.

The pseudo-channel =>PLUGIN_INSTANCE_CONFIG= is used to specify the
configuration of the plugin for tests; currently it has to occur in the first
line.
***** Json config params
It is possible to effect =config= changes and modify the routing key for a
channel to a message by specifying a json-dictionary of the form:
#+BEGIN_SRC io
>input{"config": {"regexp": ...}, "rk": ...}	some message
#+END_SRC
Note that the json must be on a single line.

***** Converting an io session into a functional test
You can create and run a test by pasting the contents of a
=plugin_test_harness.py= session by pasting the contents of the session
(you'll probably want to run without =--verbose== though) into a file (say
=test_transcript.io=) and executing the following command:

=python bin/plugin_test_harness.py -v plugins/my_plugin --test plugins/my_plugin/test_transcript.io=

This will check that the inputs give the same outputs as those listen in the
transcript and show testfailures otherwise (thanks to the =-v= or =--verbose=
flag). A more convenient way to run all tests in one or several directories is
provided by =bin/test_plugin plugins/my_plugin plugins/my_other_plugin ...=.

*NB:* you need to make sure that the first non-comment line of your =.io= file
contains the plugin-instance-configuration, i.e. it must look something like
this (where =...= denotes truncation):
#BEGIN_SRC io
>PLUGIN_INSTANCE_CONFIG	{"dotall": false, "regexp": "(.)\\1\\1", ...
#END_SRC

=make test-plugins= will automatically run all files of the form
=plugins/*/tests/*.io= as unittests. See e.g.
[[../plugins/regexp_replace/tests/test_regexp_replace.io]] for an example.

Emacs users might want to investigate =share/emacs/io-mode.el= which provides
syntax-highlighting and other facilities for manually writing =.io= files.

#+END_SRC
*** Writing Harnesses to add Plugin support for new languages
Each environment (e.g., Java, Python) in which plugins run needs a
harness.  Minimally, this is simply a shell script that starts a
plugin process given a plugin name.

The harness also provides some abstraction of the services needed by
plugins; e.g., hooking up communications channels, storing documents.
This abstraction -- a base class, say -- encapsulates the conventions
for how plugins are initialised, communicated with, and so on, letting
the plugin developer be concerned only with the specific task of the
plugin.

The set of harness and plugin conventions is currently a moving
target; however, in general, the Python and Java harnesses (and this
document) will be kept up-to-date.

***** Harness invocation

The type of the harness is indicated by the plugin descriptor
=plugin.js= in the plugin directory.  The name is treated as a
directory under =harness/=, and the file =run_plugin.sh= in that
directory is invoked.  The plugin configuration is then printed, as
JSON, to that process's =stdin=. For example, the file
=plugins/xslt/plugin.js= specifies the name of the harness as =java=
and so that plugin will be launched by the =Orchestrator= calling
=run_plugin.sh= in the directory =harness/java=.

The harness, then, must /at least/ read the configuration, extract the
plugin name (and use it as a directory under =plugins/=), and run the
plugin code, supplying the configuration in an appropriate form.  It
may also need to set environment variables, load modules, and so on.

Each harness will have its own convention for how to run a plugin
given its name.  For example, the Python harness treats the plugin
name as the directory *and* as a module name, under which it (by
convention) expects to find a callable named =run=, which it invokes
with the arguments as a dictionary.  It also puts the harness
directory on the =PYTHON_PATH= so that the plugin base class can be
imported, as well as =lib/= in the plugin directory; and, it changes
the working directory to the plugin directory so that resources can be
loaded relative to that directory.

One of the first things that a harness must do, is to print out its
/PID/ on =STDOUT=. This is picked up by the orchestrator, and used to
kill the plugin, should it be necessary to do so. Some programming
languages make it tricky to get hold of the /PID/ and as a result, we
ask the shell script, =run_plugin.sh= to supply the /PID/ as an
argument to the plugin harness. For example, the file
=harness/java/run_plugin.sh= contains:

: exec java -cp feedshub_harness.jar net.lshift.feedshub.harness.Run $$

After the harness has printed out its /PID/, it should continue with
the startup of the plugin itself. It should also create a thread that
sits, blocking on its =STDIN= file descriptor, and as soon as that
file descriptor has been closed, the harness should terminate. This is
the preferred means through which the Orchestrator stops plugins.

***** Harness services

The harness also provides convenience APIs for interacting with the
system. In principle, following the invocation convention -- e.g., for
Python, providing a correctly-named module with a run(args) procedure
-- is enough. But many details of the configuration can be taken care
of for the plugin developer.

******* Instance configuration

An instance of the plugin may have configuration specific to that
instance. (This is due to be tidied up)

This is supplied by the orchestrator, and should be exposed
read-only to the plugin code.

******* Channels

The plugin descriptor, =plugin.js=, specifies named input and output
channels required by an instance of the plugin. E.g.,

:    ...
:    "inputs": [{"name": "in"}],
:    "outputs": [{"name": "result"}],
:    ...

The orchestrator constructs input channels as AMQP queues, and output channels
as AMQP exchanges. The names of these queues and exchanges are supplied as
part of the initialisation configuration as map values (with =plugin.js=
specified channel names as keys); e.g.,

:    {...
:    "inputs" : {"in": $SOME_QUEUE_NAME},
:    "outputs" :{"result": $SOME_EXCHANGE_NAME}
:    ...}


Note that the queue and exchange names will in general be arbitrary,
and that they are supplied in an ordered list.  The harness must refer
to the plugin descriptor to match the queue or exchange to the named
channel. One way to think of this is that the =plugin.js= file
specifies the type, or class of the available connections to and from
the plugin, and the initialisation configuration contains instances of
these types or classes.

Giving the plugin programmer access to the channels in a convenient
way will depend on the capabilities of the environment. The Python
harness lets the plugin developer supply a maps of channel names to
method names; input channels use the named method as a callback, and
output channels are inserted into the object as methods. The Java
harness similarly uses reflection to attach =Publisher= objects to the
plugin's fields for outputs, and dynamically looks up inputs, where
the field names are the names of the channels given in the =plugin.js=
specification.

********* Notification Channel
Because the =STDOUT= file descriptor of the plugin is captured by the
Orchestrator, it is not recommended to output text or debugging
information though simply printing messages out. Instead, an
independent notification exchange is provided to which messages can be
sent. This exchange is called =feedshub/log= and is not supplied in
the initialisation configuration. This is a topic exchange, and so the
messages must have a routing key. The routing key should be
=loglevel.feedID.pluginName.nodeID= where loglevel is one of =debug=,
=info=, =warn=, =error=, =fatal=, and the three other components take
the values supplied in the corresponding fields in the initialisation
configuration. By using this scheme, it (currently potentially) allows
the orchestrator to filter and select messages.

The harness should try and present a suitable API to the plugin such
that the plugin has the ability to send such informational
messages. Both the Python and Java harnesses have methods for each of
the five different log levels, filling in the other components of
routing key automatically, and including any message supplied.

Additionally, the harness should try and catch any errors that the
plugin produces, sending such messages out on this exchange. Messages
should be marked with =delivery mode= 2 (or /persistent/) to make sure
messages are not lost. We recommend using a separate AMQP channel for
this exchange so that if you wish to treat messages sent by the plugin
in its normal course of operation as transactional, then this does not
force notification messages to also become transactional.

***** State
A plugin instance gets a document in which to store its running
state. This state will persist over restarts, and will be visible to
management interfaces. It should be exposed as read-write.

TODO Avoiding conflicts -- maybe the state is the argument and result
of any callback (and these are serialised)?
***** Storage

The plugin descriptor can also specify a storage database private to
each instance. The orchestrator provides the name of this database in
the initialisation configuration.

TODO safe ways of exposing this to the plugin developer.
*** TODO The Streams Architecture in more detail
#+CAPTION: Information flow (the almost full picture)
#+LABEL:   fig:flow
    [[./flow.png]]

This diagram, apart from giving more detail than [[Fig:flow-simplified]] also
shows that in the actual implementation the flow of information from Sources
to Sinks is more complicated (for practical reasons such as resource usage).
In particular

 - =Terminals= are really "passive" components that do not directly connect to
   an =AMQP Exchange=, instead each Server instance owns an =AMQP Exchange=
   with /binding keys/ for each terminal (the key is the Terminal ID). This
   is done because Exchanges are comparatively expensive resources and having
   one per server instance is less wasteful than having one per Terminal.

 - Similarly on the Egress side, there is a =Shoveler= process which takes
   care of transferring the feed data to the Terminals/Server but that can
   also be considered as an implementation detail.

* Footnotes

[fn:1] *FIXME* the aim is to just provide abstract interfaces to generic
database and messaging services to =Plugin= writers but this isn't fully the
case presently.

